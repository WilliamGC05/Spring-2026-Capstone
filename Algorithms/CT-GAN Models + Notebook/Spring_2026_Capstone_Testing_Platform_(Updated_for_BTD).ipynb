{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is our notebook that allows us to test the previously trained algorithms against different datasets. You will need some things before starting to run the code:\n",
        "- You will need the .joblib algorithm files from the previoius notebook and upload them into here\n",
        "- You will need to download the datasets you want to test the algorithms with.\n",
        "  - Note: It will take a while to upload the dataset zip files (for me some took 30 minutes to 1 hour +), so be patient and keep the window open while it is uploading. Try to not allow your computer to go to sleep because that might interrupt the upload and you will have to restart.\n",
        "\n",
        "You will also have to pay attention to where you are telling the code what directory you want to pull a algorithm or dataset from. I will tell you exactly what in the code needs to be changed if you want to test different algorithms or datasets.\n",
        "\n",
        "---\n",
        "\n",
        "For the first block of code, this just allow us to upload the .joblib algorithm files. Just run the code and upload the algorithm and it will go into the \"content/models\" folder automatically."
      ],
      "metadata": {
        "id": "07hkzV9JHrgw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "-gRsSRu-bot2",
        "outputId": "c265f03b-3262-41f7-b810-059a4a46103f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6ffb78d4-6b7c-4178-b75e-101aff48fed7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6ffb78d4-6b7c-4178-b75e-101aff48fed7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving knn_tamper_detector_CT.joblib to knn_tamper_detector_CT.joblib\n",
            "total 34M\n",
            "drwxr-xr-x 2 root root 4.0K Jan 31 13:31 .\n",
            "drwxr-xr-x 1 root root 4.0K Jan 31 13:31 ..\n",
            "-rw-r--r-- 1 root root  73K Jan 31 13:31 dt_tamper_detector_CT.joblib\n",
            "-rw-r--r-- 1 root root 1.4M Jan 31 13:31 knn_tamper_detector_CT.joblib\n",
            "-rw-r--r-- 1 root root 1.7K Jan 31 13:31 logreg_tamper_detector_CT.joblib\n",
            "-rw-r--r-- 1 root root  32M Jan 31 13:30 rf_tamper_detector_CT.joblib\n",
            "-rw-r--r-- 1 root root 583K Jan 31 13:31 svm_tamper_detector_CT.joblib\n"
          ]
        }
      ],
      "source": [
        "# Spring 2026 Capstone\n",
        "# William Carroll\n",
        "# Jessica Brown\n",
        "# Sydney Halupa\n",
        "\n",
        "from google.colab import files\n",
        "import os, shutil\n",
        "\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "\n",
        "uploaded = files.upload()  # pick your .joblib files\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    if fn.lower().endswith(\".joblib\"):\n",
        "        shutil.move(f\"/content/{fn}\", f\"/content/models/{fn}\")\n",
        "\n",
        "!ls -lah /content/models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are able to upload the datasets we want to test against the algorithms. Again, be prepared to be uploading for more than 30 minutes, especially if the dataset is close to 1 TB. Once downloaded, it will save a zip file here and place the dataset into \"content/datasets\". However, try to keep the window open and active because if your runtime ends on Google Colab it will wipe everything and you will have to redownload the dataset.\n",
        "\n",
        "---\n",
        "**What Needs to Change**\n",
        "\n",
        "If you want to name the dataset correctly then you will need to change \"DATA_DIR\". Optionally, if you want to see what is inside the dataset you just downloaded, then you would need to change the lines:\n",
        "- !find /content/datasets/... -maxdepth 3 -type d | head -n 80\n",
        "- !find /content/datasets/... -type f | head -n 40\n",
        "\n",
        "For example, If I download the \"Tampered_Covid\" dataset and I wanted to name it as such, then the DATA_DIR would look like:\n",
        "- DATA_DIR = \"/content/datasets/Tampered_Covid\"\n",
        "\n",
        "And if you want to see the output of the \"Tampered_Covid\" dataset, then the two lines that would need to change to are:\n",
        "- !find /content/datasets/Tampered_Covid -maxdepth 3 -type d | head -n 80\n",
        "- !find /content/datasets/Tampered_Covid -type f | head -n 40\n",
        "\n",
        "Note: Whenever you want to add another dataset, you MUST change the DATA_DIR directory if you want to make the dataset you are uploading separate from previously uploaded ones. Otherwise, it will write over the dataset that is currently in that path."
      ],
      "metadata": {
        "id": "eLUZfUM1Jm2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os, zipfile\n",
        "\n",
        "# ==========================================\n",
        "# CHANGE THIS LINE\n",
        "# ==========================================\n",
        "DATA_DIR = \"/content/datasets/Med_Tampered\"\n",
        "# ==========================================\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "uploaded = files.upload()  # select the dataset zip\n",
        "\n",
        "zip_name = [k for k in uploaded.keys() if k.lower().endswith(\".zip\")][0]\n",
        "zip_path = f\"/content/{zip_name}\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(DATA_DIR)\n",
        "\n",
        "print(\"Extracted to:\", DATA_DIR)\n",
        "# ==========================================\n",
        "# CHANGE THESE TWO LINES\n",
        "# ==========================================\n",
        "!find /content/datasets/... -maxdepth 3 -type d | head -n 80\n",
        "!find /content/datasets/... -type f | head -n 40\n",
        "# ==========================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jeA2RG0cPS8H",
        "outputId": "313c724e-20a4-48d4-aa1a-817da9f4ef9f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-87d64572-61b5-4475-a850-792cc7f368b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-87d64572-61b5-4475-a850-792cc7f368b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving MedicalImageTamper.zip to MedicalImageTamper.zip\n",
            "Extracted to: /content/datasets/Med_Tampered\n",
            "/content/datasets/...\n",
            "/content/datasets/.../MRI\n",
            "/content/datasets/.../MRI/Signa HDxt\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_025\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_151\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_309\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_038\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_130\n",
            "/content/datasets/.../MRI/Optima MR450w\n",
            "/content/datasets/.../MRI/Optima MR450w/Breast_MRI_118\n",
            "/content/datasets/.../MRI/Optima MR450w/Breast_MRI_856\n",
            "/content/datasets/.../MRI/Optima MR450w/Breast_MRI_573\n",
            "/content/datasets/.../MRI/Optima MR450w/Breast_MRI_712\n",
            "/content/datasets/.../MRI/Optima MR450w/Breast_MRI_508\n",
            "/content/datasets/.../MRI/Optima MR450w/Breast_MRI_339\n",
            "/content/datasets/.../MRI/Optima MR450w/Breast_MRI_187\n",
            "/content/datasets/.../MRI/SIGNA HDx\n",
            "/content/datasets/.../MRI/SIGNA HDx/Breast_MRI_303\n",
            "/content/datasets/.../MRI/SIGNA HDx/Breast_MRI_254\n",
            "/content/datasets/.../MRI/SIGNA HDx/Breast_MRI_242\n",
            "/content/datasets/.../MRI/SIGNA HDx/Breast_MRI_319\n",
            "/content/datasets/.../MRI/SIGNA HDx/Breast_MRI_296\n",
            "/content/datasets/.../MRI/SIGNA HDx/Breast_MRI_281\n",
            "/content/datasets/.../MRI/Avanto\n",
            "/content/datasets/.../MRI/Avanto/Breast_MRI_534\n",
            "/content/datasets/.../MRI/Avanto/Breast_MRI_153\n",
            "/content/datasets/.../MRI/Avanto/Breast_MRI_044\n",
            "/content/datasets/.../MRI/Avanto/Breast_MRI_039\n",
            "/content/datasets/.../MRI/Avanto/Breast_MRI_526\n",
            "/content/datasets/.../CT\n",
            "/content/datasets/.../CT/removal\n",
            "/content/datasets/.../CT/removal/FB_SD\n",
            "/content/datasets/.../CT/removal/TB\n",
            "/content/datasets/.../CT/removal/FB_CTGAN\n",
            "/content/datasets/.../CT/injection\n",
            "/content/datasets/.../CT/injection/FM_SD\n",
            "/content/datasets/.../CT/injection/TM\n",
            "/content/datasets/.../CT/injection/FM_CTGAN\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/injection_120.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/118.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/116_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/120_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/115.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/120.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/121.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/115_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/119.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/injection_115.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/injection_116.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/118_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/injection_118.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/injection_121.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/injection_117.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/119_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/121_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/116.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/117_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/117.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_162/injection_119.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/injection_120.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/118.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/116_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/120_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/115.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/120.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/121.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/115_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/119.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/injection_115.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/injection_116.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/118_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/injection_118.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/injection_121.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/injection_117.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/119_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/121_fake.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/116.png\n",
            "/content/datasets/.../MRI/Signa HDxt/Breast_MRI_243/117_fake.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 3rd block allow us to spit the dataset into the respective splits. The code should be able to distinguish tampered vs untampered datasets, but please double check the output if it throws errors, there's a chance that something might not work and we would need to add a detector to detect the dataset format (because some are weirdly set up and no two are the same structurally).\n",
        "\n",
        "---\n",
        "**What Needs to Change**\n",
        "\n",
        "At the top you should see:\n",
        "- BASE_DIR = \"/content/datasets/...\"\n",
        "- OUT_DIR  = \"/content/splits/...\"\n",
        "\n",
        "BASE_DIR is where you are directing the code to the DATASET you want to split, OUT_DIR is telling the code WHERE to put the dataset.\n",
        "\n",
        "For example, if I downloaded a dataset called \"Tampered_Covid\" located in the directory \"/content/datasets/Tampered_Covid\" then the BASE_DIR would be:\n",
        "- BASE_DIR = \"/content/datasets/Tampered_Covid\"\n",
        "\n",
        "Then lets say I want to split that dataset into the \"splits\" folder named \"Tampered_Covid_Split\", the OUT_DIR would be:\n",
        "- OUT_DIR  = \"/content/splits/Tampered_Covid_Split\""
      ],
      "metadata": {
        "id": "zljw3VsEKSEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# =========================\n",
        "# CHANGE THESE TWO LINES\n",
        "# =========================\n",
        "BASE_DIR = \"/content/datasets/Med_Tampered\"\n",
        "OUT_DIR  = \"/content/splits/Med_Tampered_TEST\"\n",
        "# =========================\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TRAIN_RATIO, VAL_RATIO, TEST_RATIO = 0.70, 0.15, 0.15\n",
        "assert abs((TRAIN_RATIO + VAL_RATIO + TEST_RATIO) - 1.0) < 1e-9\n",
        "\n",
        "USE_SYMLINKS = True\n",
        "\n",
        "IMG_EXTS   = (\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\")\n",
        "DICOM_EXTS = (\".dcm\",)\n",
        "NPY_EXTS   = (\".npy\",)\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def files_with_exts(root, exts):\n",
        "    # case-insensitive extension match\n",
        "    all_files = glob(os.path.join(root, \"**\", \"*\"), recursive=True)\n",
        "    exts_l = tuple(e.lower() for e in exts)\n",
        "    return sorted([p for p in all_files if os.path.isfile(p) and p.lower().endswith(exts_l)])\n",
        "\n",
        "def all_data_files(root):\n",
        "    return (files_with_exts(root, IMG_EXTS) +\n",
        "            files_with_exts(root, DICOM_EXTS) +\n",
        "            files_with_exts(root, NPY_EXTS))\n",
        "\n",
        "def ensure_empty_dir(path):\n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def safe_link_or_copy(src, dst):\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    if os.path.exists(dst):\n",
        "        return\n",
        "    if USE_SYMLINKS:\n",
        "        os.symlink(src, dst)\n",
        "    else:\n",
        "        shutil.copy2(src, dst)\n",
        "\n",
        "def split_stratified_or_clean_only(df):\n",
        "    # df must have filepath,label\n",
        "    if df[\"label\"].nunique() == 1:\n",
        "        # clean-only OR tampered-only dataset: split without stratify\n",
        "        train_df, tmp_df = train_test_split(df, test_size=(1-TRAIN_RATIO), random_state=RANDOM_SEED, shuffle=True)\n",
        "        val_frac = VAL_RATIO / (VAL_RATIO + TEST_RATIO)\n",
        "        val_df, test_df = train_test_split(tmp_df, test_size=(1-val_frac), random_state=RANDOM_SEED, shuffle=True)\n",
        "    else:\n",
        "        train_df, tmp_df = train_test_split(\n",
        "            df, test_size=(1-TRAIN_RATIO), random_state=RANDOM_SEED, stratify=df[\"label\"]\n",
        "        )\n",
        "        val_frac = VAL_RATIO / (VAL_RATIO + TEST_RATIO)\n",
        "        val_df, test_df = train_test_split(\n",
        "            tmp_df, test_size=(1-val_frac), random_state=RANDOM_SEED, stratify=tmp_df[\"label\"]\n",
        "        )\n",
        "\n",
        "    train_df = train_df.assign(split=\"train\")\n",
        "    val_df   = val_df.assign(split=\"val\")\n",
        "    test_df  = test_df.assign(split=\"test\")\n",
        "    return pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "def write_split_folders(df, out_dir):\n",
        "    ensure_empty_dir(out_dir)\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        src   = row[\"filepath\"]\n",
        "        split = row[\"split\"]\n",
        "        label = int(row[\"label\"])\n",
        "        cls   = \"clean\" if label == 0 else \"tampered\"\n",
        "\n",
        "        base = os.path.basename(src)\n",
        "        out_name = f\"{i:08d}_{base}\"\n",
        "        dst = os.path.join(out_dir, split, cls, out_name)\n",
        "        safe_link_or_copy(src, dst)\n",
        "\n",
        "    def count_files(p):\n",
        "        return len([x for x in glob(os.path.join(p, \"*\")) if os.path.isfile(x)])\n",
        "\n",
        "    print(\"\\nFinal counts:\")\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        for cls in [\"clean\",\"tampered\"]:\n",
        "            p = os.path.join(out_dir, split, cls)\n",
        "            print(f\"{split:5s} {cls:8s}:\", count_files(p))\n",
        "\n",
        "# ---------- detectors ----------\n",
        "def detect_already_split_layout(base_dir):\n",
        "    # base_dir/{train,val,test}/{clean,tampered}/...\n",
        "    ok = all(os.path.isdir(os.path.join(base_dir, s)) for s in [\"train\",\"val\",\"test\"])\n",
        "    if not ok:\n",
        "        return None\n",
        "    rows = []\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        for cls, lab in [(\"clean\",0),(\"tampered\",1)]:\n",
        "            p = os.path.join(base_dir, split, cls)\n",
        "            if not os.path.isdir(p):\n",
        "                continue\n",
        "            # <<< UPDATED: include npy too\n",
        "            files = all_data_files(p)\n",
        "            for f in files:\n",
        "                rows.append({\"filepath\": f, \"label\": lab, \"split\": split})\n",
        "    if len(rows) == 0:\n",
        "        return None\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def detect_image_tamper_dataset(base_dir):\n",
        "    # Kaggle \"image-tamper-dataset\": original + tamper folders\n",
        "    clean_dir = os.path.join(base_dir, \"original\")\n",
        "    tamp_dirs = [os.path.join(base_dir, x) for x in [\"copy_move\",\"copy_paste\",\"content_removal\",\"text_addition\"]]\n",
        "    if not os.path.isdir(clean_dir):\n",
        "        return None\n",
        "    tamp_dirs = [d for d in tamp_dirs if os.path.isdir(d)]\n",
        "    if len(tamp_dirs) == 0:\n",
        "        return None\n",
        "\n",
        "    clean = all_data_files(clean_dir)\n",
        "    tamp = []\n",
        "    for d in tamp_dirs:\n",
        "        tamp += all_data_files(d)\n",
        "\n",
        "    if len(clean) == 0 or len(tamp) == 0:\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame({\"filepath\": clean + tamp, \"label\": ([0]*len(clean)) + ([1]*len(tamp))})\n",
        "    return df\n",
        "\n",
        "def detect_clean_tampered_folders_anywhere(base_dir):\n",
        "    # finds any folders named clean and tampered under base_dir\n",
        "    clean_dirs = [d for d in glob(os.path.join(base_dir, \"**\", \"clean\"), recursive=True) if os.path.isdir(d)]\n",
        "    tamp_dirs  = [d for d in glob(os.path.join(base_dir, \"**\", \"tampered\"), recursive=True) if os.path.isdir(d)]\n",
        "    if len(clean_dirs) == 0 or len(tamp_dirs) == 0:\n",
        "        return None\n",
        "\n",
        "    clean, tamp = [], []\n",
        "    for d in clean_dirs:\n",
        "        clean += all_data_files(d)\n",
        "    for d in tamp_dirs:\n",
        "        tamp  += all_data_files(d)\n",
        "\n",
        "    if len(clean) == 0 or len(tamp) == 0:\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame({\"filepath\": clean + tamp, \"label\": ([0]*len(clean)) + ([1]*len(tamp))})\n",
        "    return df\n",
        "\n",
        "def detect_by_top_folder_rules(base_dir, clean_folders, tampered_prefixes=()):\n",
        "    # labels by top-level folder name under base_dir\n",
        "    all_files = all_data_files(base_dir)\n",
        "    if len(all_files) == 0:\n",
        "        return None\n",
        "\n",
        "    clean, tamp = [], []\n",
        "    for f in all_files:\n",
        "        rel = os.path.relpath(f, base_dir)\n",
        "        top = rel.split(os.sep)[0].lower()\n",
        "\n",
        "        if top in {x.lower() for x in clean_folders}:\n",
        "            clean.append(f)\n",
        "        elif any(top.startswith(p.lower()) for p in tampered_prefixes):\n",
        "            tamp.append(f)\n",
        "\n",
        "    if len(clean) == 0 or len(tamp) == 0:\n",
        "        # allow fallback if it's untampered-only\n",
        "        if len(clean) == 0 and len(tamp) == 0:\n",
        "            return None\n",
        "        if len(tamp) == 0 and len(clean) > 0:\n",
        "            # clean-only dataset\n",
        "            return pd.DataFrame({\"filepath\": clean, \"label\": [0]*len(clean)})\n",
        "        return None\n",
        "\n",
        "    return pd.DataFrame({\"filepath\": clean + tamp, \"label\": ([0]*len(clean)) + ([1]*len(tamp))})\n",
        "\n",
        "def detect_untampered_only(base_dir):\n",
        "    # last resort: treat everything as clean\n",
        "    all_files = all_data_files(base_dir)\n",
        "    if len(all_files) == 0:\n",
        "        return None\n",
        "    return pd.DataFrame({\"filepath\": all_files, \"label\": [0]*len(all_files)})\n",
        "\n",
        "# BTD DETECTOR\n",
        "def _find_dir_named_anywhere(root, target_name):\n",
        "    target = target_name.lower()\n",
        "    for dirpath, dirnames, _ in os.walk(root):\n",
        "        for dn in dirnames:\n",
        "            if dn.lower() == target:\n",
        "                return os.path.join(dirpath, dn)\n",
        "    return None\n",
        "\n",
        "def _find_child_dir_ci(parent, name):\n",
        "    if not os.path.isdir(parent):\n",
        "        return None\n",
        "    target = name.lower()\n",
        "    for dn in os.listdir(parent):\n",
        "        p = os.path.join(parent, dn)\n",
        "        if os.path.isdir(p) and dn.lower() == target:\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def _collect_files_from_dirs(dirs):\n",
        "    out = []\n",
        "    for d in dirs:\n",
        "        out += all_data_files(d)\n",
        "    return sorted(set(out))\n",
        "\n",
        "def _make_df(clean_dirs, tampered_dirs):\n",
        "    clean_files = _collect_files_from_dirs(clean_dirs)\n",
        "    tamp_files  = _collect_files_from_dirs(tampered_dirs)\n",
        "    if len(clean_files) == 0 or len(tamp_files) == 0:\n",
        "        return None\n",
        "    return pd.DataFrame({\n",
        "        \"filepath\": clean_files + tamp_files,\n",
        "        \"label\": ([0]*len(clean_files)) + ([1]*len(tamp_files))\n",
        "    })\n",
        "\n",
        "def _find_ct_root_for_btd(base_dir):\n",
        "    ct0 = _find_child_dir_ci(base_dir, \"CT\")\n",
        "    candidates = [ct0] if ct0 else []\n",
        "    ct_any = _find_dir_named_anywhere(base_dir, \"CT\")\n",
        "    if ct_any and ct_any not in candidates:\n",
        "        candidates.append(ct_any)\n",
        "\n",
        "    for ct in candidates:\n",
        "        inj = _find_child_dir_ci(ct, \"injection\")\n",
        "        rem = _find_child_dir_ci(ct, \"removal\")\n",
        "        if not inj or not rem:\n",
        "            continue\n",
        "        if _find_child_dir_ci(inj, \"TM\") and _find_child_dir_ci(rem, \"TB\"):\n",
        "            return ct\n",
        "    return None\n",
        "\n",
        "def detect_btd_all(base_dir):\n",
        "    \"\"\"\n",
        "    Returns df(filepath,label) for BTD (clean vs tampered), combining:\n",
        "      CT injection: TM vs FM_CTGAN, TM vs FM_SD\n",
        "      CT removal  : TB vs FB_CTGAN, TB vs FB_SD\n",
        "    \"\"\"\n",
        "    ct_root = _find_ct_root_for_btd(base_dir)\n",
        "    if not ct_root:\n",
        "        return None\n",
        "\n",
        "    inj = _find_child_dir_ci(ct_root, \"injection\")\n",
        "    rem = _find_child_dir_ci(ct_root, \"removal\")\n",
        "\n",
        "    tm = _find_child_dir_ci(inj, \"TM\")\n",
        "    fm_ctgan = _find_child_dir_ci(inj, \"FM_CTGAN\")\n",
        "    fm_sd    = _find_child_dir_ci(inj, \"FM_SD\")\n",
        "\n",
        "    tb = _find_child_dir_ci(rem, \"TB\")\n",
        "    fb_ctgan = _find_child_dir_ci(rem, \"FB_CTGAN\")\n",
        "    fb_sd    = _find_child_dir_ci(rem, \"FB_SD\")\n",
        "\n",
        "    dfs = []\n",
        "    if tm and fm_ctgan:\n",
        "        df = _make_df([tm], [fm_ctgan])\n",
        "        if df is not None: dfs.append(df)\n",
        "    if tm and fm_sd:\n",
        "        df = _make_df([tm], [fm_sd])\n",
        "        if df is not None: dfs.append(df)\n",
        "    if tb and fb_ctgan:\n",
        "        df = _make_df([tb], [fb_ctgan])\n",
        "        if df is not None: dfs.append(df)\n",
        "    if tb and fb_sd:\n",
        "        df = _make_df([tb], [fb_sd])\n",
        "        if df is not None: dfs.append(df)\n",
        "\n",
        "    if len(dfs) == 0:\n",
        "        return None\n",
        "\n",
        "    mri_root = _find_child_dir_ci(base_dir, \"MRI\") or _find_dir_named_anywhere(base_dir, \"MRI\")\n",
        "    print(\"BTD CT root detected at:\", ct_root)\n",
        "    if mri_root:\n",
        "        print(\"BTD MRI root detected at:\", mri_root)\n",
        "\n",
        "    df_all = pd.concat(dfs, ignore_index=True).drop_duplicates(subset=[\"filepath\"]).reset_index(drop=True)\n",
        "    return df_all\n",
        "\n",
        "# ---------- main ----------\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n",
        "print(\"OUT_DIR :\", OUT_DIR)\n",
        "print(\"Link mode:\", \"symlink\" if USE_SYMLINKS else \"copy\")\n",
        "\n",
        "# Chekcs if the dataset is already split\n",
        "df0 = detect_already_split_layout(BASE_DIR)\n",
        "if df0 is not None:\n",
        "    print(\"Using existing split layout (no re-splitting). Rows:\", len(df0))\n",
        "    display(df0.head())\n",
        "    raise SystemExit\n",
        "\n",
        "# BTD HANDLING\n",
        "df_btd = detect_btd_all(BASE_DIR)\n",
        "if df_btd is not None:\n",
        "    print(\"Detected BTD rows:\", len(df_btd), \" label counts:\", df_btd[\"label\"].value_counts().to_dict())\n",
        "\n",
        "    df_split = split_stratified_or_clean_only(df_btd)\n",
        "    df_split.to_csv(OUT_DIR + \"_manifest.csv\", index=False)\n",
        "    print(\"Saved manifest:\", OUT_DIR + \"_manifest.csv\")\n",
        "\n",
        "    write_split_folders(df_split, OUT_DIR)\n",
        "    print(\"\\nDone. Splits ready at:\", OUT_DIR)\n",
        "    raise SystemExit\n",
        "\n",
        "# Try known tamper datasets\n",
        "df = detect_image_tamper_dataset(BASE_DIR)\n",
        "if df is None:\n",
        "    df = detect_clean_tampered_folders_anywhere(BASE_DIR)\n",
        "\n",
        "# Optional: add one dataset-specific rule-set here (easy to extend)\n",
        "# Example: COVID forgery 9classes style:\n",
        "if df is None:\n",
        "    df = detect_by_top_folder_rules(\n",
        "        BASE_DIR,\n",
        "        clean_folders=[\"COVID-19\", \"Normal\", \"Viral\"],\n",
        "        tampered_prefixes=[\"F \"]  # matches \"F CM ...\", \"F S ...\"\n",
        "    )\n",
        "\n",
        "# If still nothing: treat as untampered-only\n",
        "if df is None:\n",
        "    df = detect_untampered_only(BASE_DIR)\n",
        "    print(\"No tamper labels detected. Treating dataset as CLEAN-ONLY.\")\n",
        "\n",
        "print(\"Detected rows:\", len(df), \" label counts:\", df[\"label\"].value_counts().to_dict())\n",
        "\n",
        "df_split = split_stratified_or_clean_only(df)\n",
        "df_split.to_csv(OUT_DIR + \"_manifest.csv\", index=False)\n",
        "print(\"Saved manifest:\", OUT_DIR + \"_manifest.csv\")\n",
        "\n",
        "write_split_folders(df_split, OUT_DIR)\n",
        "print(\"\\nDone. Splits ready at:\", OUT_DIR)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mFS1q6yziMS",
        "outputId": "3518d11d-9297-47c1-c7b1-0048d49a7347"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE_DIR: /content/datasets/Med_Tampered\n",
            "OUT_DIR : /content/splits/Med_Tampered_TEST\n",
            "Link mode: symlink\n",
            "Detected rows: 13030  label counts: {1: 10424, 0: 2606}\n",
            "Saved manifest: /content/splits/Med_Tampered_TEST_manifest.csv\n",
            "\n",
            "Final counts:\n",
            "train clean   : 1824\n",
            "train tampered: 7296\n",
            "val   clean   : 391\n",
            "val   tampered: 1564\n",
            "test  clean   : 391\n",
            "test  tampered: 1564\n",
            "\n",
            "Done. Splits ready at: /content/splits/Med_Tampered_TEST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our last block is the code that allows us to test the algorithms agaisnt the dataset splits we made earlier. Here, you will select the model and the dataset you want to test against.\n",
        "\n",
        "---\n",
        "**What Needs to Change**\n",
        "\n",
        "At the top you will see:\n",
        "- TAMPER_SPLIT_DIR = \"/content/splits/...\"\n",
        "- MODEL_PATH = \"/content/models/...\"\n",
        "\n",
        "TAMPER_SPLIT_DIR is the directory where we just created the DATSET SPLIT (not the original dataset), and the MODEL_PATH is directing the code to the MODEL you downloaded and placed within the \"/content/models/...\" folder in the beginning.\n",
        "\n",
        "For example, we will use the previously split dataset located at \"/content/splits/Tampered_Covid_Split\" and the SVM model named \"svm_tamper_detector_CT.joblib\" in \"/content/models\" the TAMPER_SPLIT_DIR would be:\n",
        "- TAMPER_SPLIT_DIR = \"/content/splits/Tampered_Covid_Split\"\n",
        "\n",
        "and the MODEL_PATH would be:\n",
        "- MODEL_PATH = \"/content/models/svm_tamper_detector_CT.joblib\""
      ],
      "metadata": {
        "id": "HnrQQ45XMiUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn scikit-image opencv-python numpy joblib tqdm pandas pydicom matplotlib\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import pydicom\n",
        "\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage.measure import shannon_entropy\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# CHANGE THESE TWO LINES\n",
        "# ==========================================\n",
        "TAMPER_SPLIT_DIR = \"/content/splits/Med_Tampered_TEST\"\n",
        "MODEL_PATH = \"/content/models/svm_tamper_detector_CT.joblib\"\n",
        "# ==========================================\n",
        "\n",
        "# Unified loader (DICOM + images + NPY) with CT-style normalization\n",
        "def load_u8_any(path: str, target_size=None):\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "\n",
        "    # --- NPY path ---\n",
        "    if ext == \".npy\":\n",
        "        try:\n",
        "            arr = np.load(path)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "        # Make sure it's 2D grayscale\n",
        "        img = arr\n",
        "\n",
        "        img = np.squeeze(img)\n",
        "\n",
        "        if img.ndim == 3 and img.shape[-1] in (1, 3):\n",
        "            if img.shape[-1] == 3:\n",
        "                img = cv2.cvtColor(img.astype(np.float32), cv2.COLOR_BGR2GRAY)\n",
        "            else:\n",
        "                img = img[..., 0]\n",
        "\n",
        "        elif img.ndim == 3 and img.shape[0] in (1, 3):\n",
        "            if img.shape[0] == 3:\n",
        "                img = np.transpose(img, (1, 2, 0))\n",
        "                img = cv2.cvtColor(img.astype(np.float32), cv2.COLOR_BGR2GRAY)\n",
        "            else:\n",
        "                img = img[0, :, :]\n",
        "\n",
        "        if img.ndim != 2:\n",
        "            return None\n",
        "\n",
        "        img = img.astype(np.float32)\n",
        "\n",
        "    # --- DICOM path ---\n",
        "    elif ext == \".dcm\":\n",
        "        try:\n",
        "            ds = pydicom.dcmread(path, force=True)\n",
        "            img = ds.pixel_array.astype(np.float32)\n",
        "\n",
        "            slope = float(getattr(ds, \"RescaleSlope\", 1.0))\n",
        "            intercept = float(getattr(ds, \"RescaleIntercept\", 0.0))\n",
        "            img = img * slope + intercept\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    # --- Normal image path ---\n",
        "    else:\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            return None\n",
        "        img = img.astype(np.float32)\n",
        "\n",
        "    # Optional: force a consistent size\n",
        "    if target_size is not None:\n",
        "        img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA).astype(np.float32)\n",
        "\n",
        "    # CT-GAN-like robust normalization (p1..p99)\n",
        "    lo = np.percentile(img, 1)\n",
        "    hi = np.percentile(img, 99)\n",
        "    if hi <= lo:\n",
        "        hi = lo + 1.0\n",
        "\n",
        "    img = np.clip(img, lo, hi)\n",
        "    img = (img - lo) / (hi - lo)\n",
        "\n",
        "    return (img * 255.0).astype(np.uint8)\n",
        "\n",
        "# Feature extraction (unchanged)\n",
        "def extract_features(img_u8: np.ndarray) -> np.ndarray:\n",
        "    if img_u8.ndim != 2:\n",
        "        img_u8 = cv2.cvtColor(img_u8, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    mean = float(np.mean(img_u8))\n",
        "    std = float(np.std(img_u8))\n",
        "    mn = float(np.min(img_u8))\n",
        "    mx = float(np.max(img_u8))\n",
        "    median = float(np.median(img_u8))\n",
        "\n",
        "    edges = cv2.Canny(img_u8, 50, 150)\n",
        "    edge_density = float(np.mean(edges > 0))\n",
        "\n",
        "    lap_var = float(cv2.Laplacian(img_u8, cv2.CV_64F).var())\n",
        "    ent = float(shannon_entropy(img_u8))\n",
        "\n",
        "    quant = (img_u8 // 16).astype(np.uint8)\n",
        "    glcm = graycomatrix(\n",
        "        quant,\n",
        "        distances=[1, 2],\n",
        "        angles=[0, np.pi/4, np.pi/2],\n",
        "        levels=16,\n",
        "        symmetric=True,\n",
        "        normed=True\n",
        "    )\n",
        "\n",
        "    contrast = float(graycoprops(glcm, \"contrast\").mean())\n",
        "    correlation = float(graycoprops(glcm, \"correlation\").mean())\n",
        "    energy = float(graycoprops(glcm, \"energy\").mean())\n",
        "    homogeneity = float(graycoprops(glcm, \"homogeneity\").mean())\n",
        "\n",
        "    return np.array([\n",
        "        mean, std, mn, mx, median,\n",
        "        edge_density, lap_var, ent,\n",
        "        contrast, correlation, energy, homogeneity\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "def get_split_files(split_name, class_name):\n",
        "    exts = [\"png\",\"jpg\",\"jpeg\",\"bmp\",\"tif\",\"tiff\",\"dcm\",\"npy\"]\n",
        "    files = []\n",
        "    for e in exts:\n",
        "        files += glob(os.path.join(TAMPER_SPLIT_DIR, split_name, class_name, f\"*.{e}\"))\n",
        "    return sorted(files)\n",
        "\n",
        "def build_Xy_from_images(clean_paths, tampered_paths, tag=\"\"):\n",
        "    X, y = [], []\n",
        "\n",
        "    for p in tqdm(clean_paths, desc=f\"{tag} CLEAN feature extraction\", unit=\"img\"):\n",
        "        img_u8 = load_u8_any(p, target_size=None)\n",
        "        if img_u8 is None:\n",
        "            continue\n",
        "        X.append(extract_features(img_u8))\n",
        "        y.append(0)\n",
        "\n",
        "    for p in tqdm(tampered_paths, desc=f\"{tag} TAMPERED feature extraction\", unit=\"img\"):\n",
        "        img_u8 = load_u8_any(p, target_size=None)\n",
        "        if img_u8 is None:\n",
        "            continue\n",
        "        X.append(extract_features(img_u8))\n",
        "        y.append(1)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def load_split(split_name):\n",
        "    clean = get_split_files(split_name, \"clean\")\n",
        "    tamp  = get_split_files(split_name, \"tampered\")\n",
        "\n",
        "    print(f\"\\n{split_name.upper()} -> using {len(clean)} clean + {len(tamp)} tampered\")\n",
        "    return build_Xy_from_images(clean, tamp, tag=split_name.upper())\n",
        "\n",
        "# Load data\n",
        "X_train, y_train = load_split(\"train\")\n",
        "X_val, y_val     = load_split(\"val\")\n",
        "X_test, y_test   = load_split(\"test\")\n",
        "\n",
        "# Load trained model\n",
        "model = joblib.load(MODEL_PATH)\n",
        "print(\"\\nLoaded model:\", MODEL_PATH)\n",
        "\n",
        "def eval_split(name, X, y):\n",
        "    preds = model.predict(X)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "\n",
        "    cm = confusion_matrix(y, preds, labels=[0,1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print(\"Confusion Matrix [[TN FP],[FN TP]]:\\n\", cm)\n",
        "\n",
        "    if y.sum() == 0:\n",
        "        fpr = fp / (tn + fp) if (tn + fp) else 0.0\n",
        "        print(f\"False Positive Rate (pred tampered on clean-only): {fpr:.4f}\")\n",
        "        print(f\"Specificity / TNR (pred clean on clean-only): {(tn/(tn+fp)):.4f}\" if (tn+fp) else \"n/a\")\n",
        "        return preds\n",
        "\n",
        "    print(classification_report(y, preds, target_names=[\"Clean\",\"Tampered\"], zero_division=0))\n",
        "    return preds\n",
        "\n",
        "train_preds = eval_split(\"TRAIN\", X_train, y_train)\n",
        "val_preds   = eval_split(\"VALIDATION\", X_val, y_val)\n",
        "test_preds  = eval_split(\"TEST\", X_test, y_test)\n",
        "\n",
        "def metrics_row(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    total = tn + fp + fn + tp\n",
        "    acc = (tn + tp) / total if total else 0.0\n",
        "\n",
        "    if int(np.sum(y_true)) == 0:\n",
        "        fpr = fp / (tn + fp) if (tn + fp) else 0.0\n",
        "        tnr = tn / (tn + fp) if (tn + fp) else 0.0\n",
        "        return {\n",
        "            \"Accuracy\": acc,\n",
        "            \"False Positive Rate\": fpr,\n",
        "            \"Specificity (TNR)\": tnr,\n",
        "            \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn), \"TP\": int(tp),\n",
        "            \"N_Clean\": int(tn + fp),\n",
        "            \"N_Tampered\": 0\n",
        "        }\n",
        "\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    tnr  = tn / (tn + fp) if (tn + fp) else 0.0\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1-score\": f1,\n",
        "        \"Specificity (TNR)\": tnr,\n",
        "        \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn), \"TP\": int(tp),\n",
        "        \"N_Clean\": int(tn + fp),\n",
        "        \"N_Tampered\": int(fn + tp)\n",
        "    }\n",
        "\n",
        "metrics_table = pd.DataFrame(\n",
        "    [metrics_row(y_train, train_preds),\n",
        "     metrics_row(y_val,   val_preds),\n",
        "     metrics_row(y_test,  test_preds)],\n",
        "    index=[\"Train\", \"Validation\", \"Test\"]\n",
        ").round(4)\n",
        "\n",
        "display(metrics_table.reset_index().rename(columns={\"index\": \"Split\"}))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, test_preds, labels=[0,1])\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(cm)\n",
        "plt.title(\"Confusion Matrix (Test)\")\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.xticks([0, 1], [\"Clean\", \"Tampered\"])\n",
        "plt.yticks([0, 1], [\"Clean\", \"Tampered\"])\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KxrIeoVb0QyZ",
        "outputId": "cb3cc5f0-0ed2-4649-8671-7c4910ede17a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAIN -> using 1824 clean + 7296 tampered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN CLEAN feature extraction: 100%|| 1824/1824 [00:19<00:00, 93.92img/s] \n",
            "TRAIN TAMPERED feature extraction: 100%|| 7296/7296 [01:14<00:00, 97.40img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "VAL -> using 391 clean + 1564 tampered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "VAL CLEAN feature extraction: 100%|| 391/391 [00:03<00:00, 102.78img/s]\n",
            "VAL TAMPERED feature extraction: 100%|| 1564/1564 [00:15<00:00, 99.08img/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEST -> using 391 clean + 1564 tampered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST CLEAN feature extraction: 100%|| 391/391 [00:04<00:00, 90.63img/s]\n",
            "TEST TAMPERED feature extraction: 100%|| 1564/1564 [00:16<00:00, 96.99img/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded model: /content/models/svm_tamper_detector_CT.joblib\n",
            "\n",
            "=== TRAIN ===\n",
            "Confusion Matrix [[TN FP],[FN TP]]:\n",
            " [[ 752 1072]\n",
            " [3082 4214]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Clean       0.20      0.41      0.27      1824\n",
            "    Tampered       0.80      0.58      0.67      7296\n",
            "\n",
            "    accuracy                           0.54      9120\n",
            "   macro avg       0.50      0.49      0.47      9120\n",
            "weighted avg       0.68      0.54      0.59      9120\n",
            "\n",
            "\n",
            "=== VALIDATION ===\n",
            "Confusion Matrix [[TN FP],[FN TP]]:\n",
            " [[150 241]\n",
            " [674 890]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Clean       0.18      0.38      0.25       391\n",
            "    Tampered       0.79      0.57      0.66      1564\n",
            "\n",
            "    accuracy                           0.53      1955\n",
            "   macro avg       0.48      0.48      0.45      1955\n",
            "weighted avg       0.67      0.53      0.58      1955\n",
            "\n",
            "\n",
            "=== TEST ===\n",
            "Confusion Matrix [[TN FP],[FN TP]]:\n",
            " [[164 227]\n",
            " [665 899]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Clean       0.20      0.42      0.27       391\n",
            "    Tampered       0.80      0.57      0.67      1564\n",
            "\n",
            "    accuracy                           0.54      1955\n",
            "   macro avg       0.50      0.50      0.47      1955\n",
            "weighted avg       0.68      0.54      0.59      1955\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Split  Accuracy  Precision  Recall  F1-score  Specificity (TNR)   TN  \\\n",
              "0       Train    0.5445     0.7972  0.5776    0.6698             0.4123  752   \n",
              "1  Validation    0.5320     0.7869  0.5691    0.6605             0.3836  150   \n",
              "2        Test    0.5437     0.7984  0.5748    0.6684             0.4194  164   \n",
              "\n",
              "     FP    FN    TP  N_Clean  N_Tampered  \n",
              "0  1072  3082  4214     1824        7296  \n",
              "1   241   674   890      391        1564  \n",
              "2   227   665   899      391        1564  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8f33ee1-a6ab-401d-8751-901e9908a0ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Split</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>Specificity (TNR)</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "      <th>N_Clean</th>\n",
              "      <th>N_Tampered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train</td>\n",
              "      <td>0.5445</td>\n",
              "      <td>0.7972</td>\n",
              "      <td>0.5776</td>\n",
              "      <td>0.6698</td>\n",
              "      <td>0.4123</td>\n",
              "      <td>752</td>\n",
              "      <td>1072</td>\n",
              "      <td>3082</td>\n",
              "      <td>4214</td>\n",
              "      <td>1824</td>\n",
              "      <td>7296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Validation</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>0.5691</td>\n",
              "      <td>0.6605</td>\n",
              "      <td>0.3836</td>\n",
              "      <td>150</td>\n",
              "      <td>241</td>\n",
              "      <td>674</td>\n",
              "      <td>890</td>\n",
              "      <td>391</td>\n",
              "      <td>1564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test</td>\n",
              "      <td>0.5437</td>\n",
              "      <td>0.7984</td>\n",
              "      <td>0.5748</td>\n",
              "      <td>0.6684</td>\n",
              "      <td>0.4194</td>\n",
              "      <td>164</td>\n",
              "      <td>227</td>\n",
              "      <td>665</td>\n",
              "      <td>899</td>\n",
              "      <td>391</td>\n",
              "      <td>1564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8f33ee1-a6ab-401d-8751-901e9908a0ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8f33ee1-a6ab-401d-8751-901e9908a0ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8f33ee1-a6ab-401d-8751-901e9908a0ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"plt\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Split\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Train\",\n          \"Validation\",\n          \"Test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0069973804622396295,\n        \"min\": 0.532,\n        \"max\": 0.5445,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5445,\n          0.532,\n          0.5437\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006321655901212361,\n        \"min\": 0.7869,\n        \"max\": 0.7984,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7972,\n          0.7869,\n          0.7984\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004331666346030483,\n        \"min\": 0.5691,\n        \"max\": 0.5776,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5776,\n          0.5691,\n          0.5748\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0050143128475727645,\n        \"min\": 0.6605,\n        \"max\": 0.6698,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6698,\n          0.6605,\n          0.6684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity (TNR)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018954946583939508,\n        \"min\": 0.3836,\n        \"max\": 0.4194,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4123,\n          0.3836,\n          0.4194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 343,\n        \"min\": 150,\n        \"max\": 752,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          752,\n          150,\n          164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 483,\n        \"min\": 227,\n        \"max\": 1072,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1072,\n          241,\n          227\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1392,\n        \"min\": 665,\n        \"max\": 3082,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3082,\n          674,\n          665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1916,\n        \"min\": 890,\n        \"max\": 4214,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4214,\n          890,\n          899\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N_Clean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 827,\n        \"min\": 391,\n        \"max\": 1824,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          391,\n          1824\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N_Tampered\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3309,\n        \"min\": 1564,\n        \"max\": 7296,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1564,\n          7296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "print(\"TAMPER_SPLIT_DIR =\", TAMPER_SPLIT_DIR)\n",
        "\n",
        "def nfiles(split, cls):\n",
        "    return len([p for p in glob(os.path.join(TAMPER_SPLIT_DIR, split, cls, \"*\")) if os.path.isfile(p)])\n",
        "\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    c = nfiles(split, \"clean\")\n",
        "    t = nfiles(split, \"tampered\")\n",
        "    print(f\"{split:5s} clean={c}  tampered={t}  total={c+t}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBX1DFsaXK8s",
        "outputId": "e849debf-4282-4ed2-ce73-3f4a0aa8d196"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TAMPER_SPLIT_DIR = /content/splits/Med_Tampered_TEST\n",
            "train clean=1824  tampered=7296  total=9120\n",
            "val   clean=391  tampered=1564  total=1955\n",
            "test  clean=391  tampered=1564  total=1955\n"
          ]
        }
      ]
    }
  ]
}